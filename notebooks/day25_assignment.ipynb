{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hand Written Digit Classification with Keras\n",
    "\n",
    "We learnt how CNNs are extremely useful in working with images data. In this series of assignments, we will experiment with different types of model to better understand the workings and advantages of CNNs.\n",
    "\n",
    "\n",
    "## Setting\n",
    "\n",
    "* We will be working with MNIST dataset, which is a labeled images of 0-9 numbers.\n",
    "* We will be using keras library to carry out modeling and training of neural networks and CNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loading necessary packages\n",
    "\n",
    "import numpy\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 42\n",
    "numpy.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify MNIST dataset using an ANN and CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Write `load_mnist` function:\n",
    "\n",
    "- The function loads mnist dataset from keras library\n",
    "- It takes in no parameters\n",
    "- Returns \n",
    "    - X_train, X_test, y_train, y_test (Numpy arrays for training, testing; any format acceptable by sklearn, keras will work)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_mnist():\n",
    "    (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = load_mnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Write `plot_mnist` function:\n",
    "\n",
    "- The function plots randomly picked 4 images from the dataset\n",
    "- It takes in no parameters\n",
    "- Returns\n",
    "    - The function plots 4 images in 2x2 fashion in a single figure\n",
    "    - also matplotlib object of the figure\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_mnist():\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.subplot(221)\n",
    "    plt.imshow(X_train[23], cmap=plt.get_cmap('gray'))\n",
    "    plt.subplot(222)\n",
    "    plt.imshow(X_train[788], cmap=plt.get_cmap('gray'))\n",
    "    plt.subplot(223)\n",
    "    plt.imshow(X_train[456], cmap=plt.get_cmap('gray'))\n",
    "    plt.subplot(224)\n",
    "    plt.imshow(X_train[234], cmap=plt.get_cmap('gray'))\n",
    "    plt.show()\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAk0AAAJCCAYAAADdrPONAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\njsRdIGV1LPkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12ace6750>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = plot_mnist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Write `flatten_normalise` function:\n",
    "\n",
    "- Next, we want to convert our feature set into a format which can be used by the ANN\n",
    "- The function flattens the dataset and normalises feature values from 0-255 to 0-1\n",
    "- Accepts feature matrix\n",
    "- Returns \n",
    "    - flattened and normalised feature matrix, where each row represents 1 observation/image.\n",
    "    \n",
    "    \n",
    "Hint: Observe how each datapoint is arranged in the feature matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def flatten_normalise(X):\n",
    "    num_pixels = X.shape[1] * X.shape[2]\n",
    "    return X.reshape(X.shape[0], num_pixels).astype('float32')/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train1 = flatten_normalise(X_train)\n",
    "X_test1 = flatten_normalise(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Write `OHE` function:\n",
    "\n",
    "- Next, we want to convert our target set into a OHE matrix\n",
    "- The function one-hot-encodes the target variable\n",
    "- Accepts numpy matrix for target variable\n",
    "- Returns \n",
    "    - One Hot Encoded target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def OHE(y):\n",
    "    return np_utils.to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train1 = OHE(y_train)\n",
    "y_test1 = OHE(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Write `baseline_model` function\n",
    "\n",
    "- Now that we have converted both the input fetures and target variable in the correct format, we can go ahead and build the baseline keras model.\n",
    "- We want to build a neural network with following architecture\n",
    "    - Layer 1: Input layer with `relu` activation function and `normal` kernel intializer\n",
    "    - Layer 2: Output layer with `softmax` activation function and `normal` kernel intializer\n",
    "    - Loss function: `categorical_crossentropy`\n",
    "    - optimizer: `adam`\n",
    "    - Metric: `accuracy`\n",
    "    - \n",
    "- Write a function `baseline_model` that\n",
    "    - Accepts:\n",
    "        - Number of input features (int)\n",
    "        - Number of output classes (int)\n",
    "        - X_train, X_test (Numpy arrays with dimension `(m x input_feature_size)` for training, testing; any format acceptable by sklearn, keras will work) (m is number of observations)\n",
    "        - y_train, y_test (Numpy arrays with dimension `(m x num_classes)` for training, testing; any format acceptable by sklearn, keras will work) (m is number of observations)\n",
    "        - number of epochs to run the model for (int) (default 10)\n",
    "    - Returns:\n",
    "        - Keras neural network model trained on X_train, y_train and validated on X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def baseline_model(input_feature_size, num_classes, X_train, X_test, y_train, y_test, epochs=10):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(input_feature_size, input_dim=input_feature_size, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(num_classes, kernel_initializer='normal', activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=epochs, batch_size=200, verbose=1)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 10s - loss: 0.2760 - acc: 0.9215 - val_loss: 0.1416 - val_acc: 0.9582\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 11s - loss: 0.1092 - acc: 0.9688 - val_loss: 0.0937 - val_acc: 0.9713\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 10s - loss: 0.0714 - acc: 0.9787 - val_loss: 0.0784 - val_acc: 0.9765\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 10s - loss: 0.0493 - acc: 0.9859 - val_loss: 0.0683 - val_acc: 0.9798\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 10s - loss: 0.0358 - acc: 0.9896 - val_loss: 0.0647 - val_acc: 0.9790\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 12s - loss: 0.0262 - acc: 0.9929 - val_loss: 0.0602 - val_acc: 0.9814\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 12s - loss: 0.0191 - acc: 0.9957 - val_loss: 0.0645 - val_acc: 0.9801\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 10s - loss: 0.0152 - acc: 0.9964 - val_loss: 0.0584 - val_acc: 0.9807\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 10s - loss: 0.0103 - acc: 0.9979 - val_loss: 0.0596 - val_acc: 0.9828\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 10s - loss: 0.0076 - acc: 0.9986 - val_loss: 0.0678 - val_acc: 0.9790\n"
     ]
    }
   ],
   "source": [
    "model = baseline_model(784, 10, X_train1, X_test1, y_train1, y_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 784)               615440    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                7850      \n",
      "=================================================================\n",
      "Total params: 623,290\n",
      "Trainable params: 623,290\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accuracy: 97.90%\n",
      "Baseline Error: 2.10%\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test1, y_test1, verbose=0)\n",
    "print(\"Baseline Accuracy: {:.2f}%\".format(scores[1]*100))\n",
    "print(\"Baseline Error: {:.2f}%\".format(100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Write `reshape_normalize` function\n",
    "\n",
    "- Next, we want to convert our feature set into a format which can be used by the CNN\n",
    "- Theano backed keras accepts feature in NCHW shape where,\n",
    "    N: number of observations\n",
    "    C: number of channels in the image\n",
    "    H: height of the image\n",
    "    W: width of the image\n",
    "- The function also normalises feature values from 0-255 to 0-1\n",
    "- Write a function `reshape_normalize` that\n",
    "    - Accepts original feature matrix in NxHxW format\n",
    "- Returns \n",
    "    - NCHW reshaped and normalised feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reshape_normalise(X):\n",
    "    X =  X.reshape(X.shape[0], 1, 28, 28).astype('float32')\n",
    "    X = X/255\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# normalize inputs from 0-255 to 0-1\n",
    "X_train2 = reshape_normalise(X_train)\n",
    "X_test2 = reshape_normalise(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Write `cnn_model` function\n",
    "\n",
    "- Now that we have converted both the input fetures and target variable in the correct format, we can go ahead and build the baseline keras model.\n",
    "- We want to build a neural network with following architecture\n",
    "    - Input Convolution Layer with 30 kernels of size 5x5\n",
    "    - Layer 2: Max Pooling with window size 2x2\n",
    "    - Layer 3: Convolution layer with 15 kernels of size 3x3\n",
    "    - Layer 4: Max Pooling with window size 2x2\n",
    "    - Layer 5: Dropout Layer\n",
    "    - Layer 6: Dense Layer with 128 neurons\n",
    "    - Layer 7: Dense Layer with 50 neurons\n",
    "    - Output Layer with neurons equal to `num_classes` \n",
    "    - Loss function: `categorical_crossentropy`\n",
    "    - optimizer: `adam`\n",
    "    - Metric: `accuracy`\n",
    "\n",
    "Note: Use appropriate activation functions for layers that require them.\n",
    "\n",
    "- Write a function `cnn_model` that\n",
    "    - Accepts:\n",
    "        - Number of output classes (int)\n",
    "        - X_train, X_test (Numpy arrays with dimension `(m x 1 x 28 x 28)` for training, testing; any format acceptable by sklearn, keras will work) (m is number of observations)\n",
    "        - y_train, y_test (Numpy arrays with dimension `(m x num_classes)` for training, testing; any format acceptable by sklearn, keras will work) (m is number of observations)\n",
    "        - number of epochs to run the model for (int) (default 10)\n",
    "        - dropout ratio (float) (default 0.2)\n",
    "    - Returns:\n",
    "        - Keras neural network model trained on X_train, y_train and validated on X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define the larger model\n",
    "def cnn_model(num_classes, X_train, X_test, y_train, y_test, epochs=5, droput_ratio=0.2):\n",
    "    \n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(30, (5, 5), input_shape=(1, 28, 28), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Convolution2D(15, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=epochs, batch_size=200, verbose=2)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "212s - loss: 0.3562 - acc: 0.8920 - val_loss: 0.0838 - val_acc: 0.9746\n",
      "Epoch 2/5\n",
      "207s - loss: 0.0974 - acc: 0.9703 - val_loss: 0.0543 - val_acc: 0.9824\n",
      "Epoch 3/5\n",
      "214s - loss: 0.0696 - acc: 0.9783 - val_loss: 0.0404 - val_acc: 0.9867\n",
      "Epoch 4/5\n",
      "235s - loss: 0.0552 - acc: 0.9832 - val_loss: 0.0346 - val_acc: 0.9889\n",
      "Epoch 5/5\n",
      "217s - loss: 0.0494 - acc: 0.9843 - val_loss: 0.0283 - val_acc: 0.9902\n"
     ]
    }
   ],
   "source": [
    "# build the model\n",
    "large_cnn_model = cnn_model(10, X_train2, X_test2, y_train1, y_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Large CNN Accuracy: 99.02%\n",
      "Large CNN Error: 0.98%\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation of the model\n",
    "large_cnn_scores = large_cnn_model.evaluate(X_test2, y_test1, verbose=0)\n",
    "print(\"Large CNN Accuracy: {:.2f}%\".format(large_cnn_scores[1]*100))\n",
    "print(\"Large CNN Error: {:.2f}%\".format(100-large_cnn_scores[1]*100))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:greyatom]",
   "language": "python",
   "name": "conda-env-greyatom-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
